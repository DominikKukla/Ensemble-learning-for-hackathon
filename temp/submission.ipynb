{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część!\n",
    "\n",
    "## Jak poprawnie odpalić ten notebook na datasecie testowym?\n",
    "\n",
    "1. Przygotuj folder z obrazkami testowymi za pomocą schematu:\n",
    "```\n",
    "| - submission.ipynb\n",
    "|\n",
    "└───test_data\n",
    "    ├───barszcz\n",
    "    ├───bigos\n",
    "    ├───grzybowa\n",
    "    ├───Kutia\n",
    "    ├───makowiec\n",
    "    ├───piernik\n",
    "    ├───pierogi\n",
    "    └───sernik\n",
    "└───models\n",
    "    ├───mobilenet_v3_large_best_f1.pth\n",
    "    ├───efficientnet_b0_best_f1.pth\n",
    "    ├───efficientnet_b1_best_f1.pth\n",
    "    ├───shufflenet_v2_x2_0_best_f1.pth\n",
    "```\n",
    "\n",
    "Proszę pilnuj tego aby nazwy folderów z klasami byli takie same jak w stukturze wyżej!\n",
    "\n",
    "2. Umieść obrazki każdej klasy w odpowidającym folderze.\n",
    "\n",
    "3. Aby urochomić poniższy kod będziesz potrzebował bibliotek z requirements.txt\n",
    "\n",
    "Możesz ich zainstalować komendą: `pip install -r requirements.txt`\n",
    "\n",
    "4. Potrzebujesz też CUDA 12.1\n",
    "\n",
    "5. Puść poniższy kod!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root_dir=\"test_data\"):\n",
    "    size_tuple = (224, 224)\n",
    "    # Define a mapping from folder names to class numbers\n",
    "    class_mapping = {\n",
    "        \"barszcz\": 1,\n",
    "        \"bigos\": 2,\n",
    "        \"Kutia\": 3,\n",
    "        \"makowiec\": 4,\n",
    "        \"piernik\": 5,\n",
    "        \"pierogi\": 6,\n",
    "        \"sernik\": 7,\n",
    "        \"grzybowa\": 8,\n",
    "    }\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Load the original dataset\n",
    "    test_dataset = datasets.ImageFolder(\n",
    "        root=root_dir,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size_tuple),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),  # Normalize\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    test_dataset.class_to_idx = {\n",
    "        k: class_mapping[k] for k in test_dataset.class_to_idx.keys()\n",
    "    }\n",
    "\n",
    "    # Create data loaders\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_classes, device):\n",
    "        self.device = device\n",
    "        self.model_weights = dict()\n",
    "\n",
    "        self.models = {\n",
    "            \"efficientnet_b0\": self._prepare_efficientnet_b0(\n",
    "                num_classes, \"efficientnet_b0\"\n",
    "            ),\n",
    "            \"efficientnet_b1\": self._prepare_efficientnet_b1(\n",
    "                num_classes, \"efficientnet_b1\"\n",
    "            ),\n",
    "            \"mobilenet_v3_large\": self._prepare_mobilenet_v3_large(\n",
    "                num_classes, \"mobilenet_v3_large\"\n",
    "            ),\n",
    "            \"shufflenet_v2_x2_0\": self._prepare_shufflenet_v2_x2_0(\n",
    "                num_classes, \"shufflenet_v2_x2_0\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def _prepare_efficientnet_b0(self, num_classes, model_name):\n",
    "        model = models.efficientnet_b0(weights=\"DEFAULT\")\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f\"models/{model_name}_best_f1.pth\")\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint[\"best_val_f1\"]\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def _prepare_efficientnet_b1(self, num_classes, model_name):\n",
    "        model = models.efficientnet_b1(weights=\"IMAGENET1K_V2\")\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f\"models/{model_name}_best_f1.pth\")\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint[\"best_val_f1\"]\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def _prepare_mobilenet_v3_large(self, num_classes, model_name):\n",
    "        model = models.mobilenet_v3_large(weights=\"IMAGENET1K_V2\")\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f\"models/{model_name}_best_f1.pth\")\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint[\"best_val_f1\"]\n",
    "\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def _prepare_shufflenet_v2_x2_0(self, num_classes, model_name):\n",
    "        model = models.shufflenet_v2_x2_0(weights=\"DEFAULT\")\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f\"models/{model_name}_best_f1.pth\")\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint[\"best_val_f1\"]\n",
    "\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def sequential_batch_evaluation(self, dataloader, batch_size=20):\n",
    "        # Total number of classes\n",
    "        num_classes = len(dataloader.dataset.classes)\n",
    "\n",
    "        # Create a list to track F1 scores for each sequential batch\n",
    "        sequential_f1_scores = []\n",
    "\n",
    "        # Get the total number of images\n",
    "        total_images = len(dataloader.dataset)\n",
    "\n",
    "        # Calculate how many full batches of 10 images per class we can process\n",
    "        images_per_class = total_images // num_classes\n",
    "        batches_per_class = images_per_class // batch_size\n",
    "\n",
    "        # Iterate through sequential batches\n",
    "        for batch_group in range(batches_per_class):\n",
    "            # Reset ensemble probabilities and labels for this batch group\n",
    "            all_ensemble_probs = defaultdict(list)\n",
    "            all_labels = []\n",
    "\n",
    "            # Process 10 images from each class\n",
    "            for class_idx in range(num_classes):\n",
    "                start_idx = (batch_group * batch_size) + (class_idx * images_per_class)\n",
    "                end_idx = start_idx + batch_size\n",
    "\n",
    "                # Create a subset for this specific slice of images\n",
    "                subset_indices = list(range(start_idx, end_idx))\n",
    "                subset = Subset(dataloader.dataset, subset_indices)\n",
    "\n",
    "                # Create a new dataloader for this subset\n",
    "                subset_loader = torch.utils.data.DataLoader(\n",
    "                    subset, batch_size=batch_size, shuffle=False\n",
    "                )\n",
    "\n",
    "                # Process this subset\n",
    "                for images, labels in subset_loader:\n",
    "                    images = images.to(self.device)\n",
    "\n",
    "                    # Collect probabilities from each model\n",
    "                    for model_name, model in self.models.items():\n",
    "                        probs = torch.softmax(model(images), dim=1)\n",
    "                        all_ensemble_probs[model_name].append(probs.detach().cpu())\n",
    "\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Normalize model weights\n",
    "            n = 5\n",
    "            self.model_weights_now = {k: v**n for k, v in self.model_weights.items()}\n",
    "            total_weight = sum(self.model_weights_now.values())\n",
    "            model_weights_normalized = {\n",
    "                model: weight / total_weight\n",
    "                for model, weight in self.model_weights_now.items()\n",
    "            }\n",
    "\n",
    "            # Calculate ensemble predictions\n",
    "            all_ensemble_preds = []\n",
    "            for i in range(len(list(all_ensemble_probs.values())[0])):\n",
    "                weighted_preds = []\n",
    "                for model_name in list(self.models.keys()):\n",
    "                    weight = model_weights_normalized.get(model_name, 0.0)\n",
    "                    if weight == 0.0:\n",
    "                        print(f\"Warning: No weight for model {model_name}\")\n",
    "                        break\n",
    "                    weighted_preds.append(all_ensemble_probs[model_name][i] * weight)\n",
    "\n",
    "                ensemble_probs = torch.sum(torch.stack(weighted_preds), dim=0)\n",
    "                _, ensemble_pred = torch.max(ensemble_probs, 1)\n",
    "                all_ensemble_preds.extend(ensemble_pred.cpu().numpy())\n",
    "\n",
    "            # Calculate F1 score for this batch group\n",
    "            batch_f1 = f1_score(all_labels, all_ensemble_preds, average=\"weighted\")\n",
    "            sequential_f1_scores.append(batch_f1)\n",
    "\n",
    "            # Print detailed report for this batch group\n",
    "            print(f\"\\nBatch Group {batch_group + 1} Results:\")\n",
    "            print(f\"Weighted Ensemble F1 Score: {batch_f1}\")\n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(\n",
    "                classification_report(\n",
    "                    all_labels, all_ensemble_preds, digits=4, zero_division=0\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Print overall summary of F1 scores\n",
    "        print(\"\\nSequential Batch F1 Scores:\")\n",
    "        print(sequential_f1_scores)\n",
    "        print(f\"Average F1 Score: {np.mean(sequential_f1_scores)}\")\n",
    "        print(f\"F1 Score Standard Deviation: {np.std(sequential_f1_scores)}\")\n",
    "\n",
    "        return sequential_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5096\\1608705122.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5096\\1608705122.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5096\\1608705122.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_5096\\1608705122.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Group 1 Results:\n",
      "Weighted Ensemble F1 Score: 0.8156297031855285\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.7500    0.7317        20\n",
      "           1     0.7692    1.0000    0.8696        20\n",
      "           2     1.0000    0.9000    0.9474        20\n",
      "           3     0.7727    0.8500    0.8095        20\n",
      "           4     0.8421    0.8000    0.8205        20\n",
      "           5     0.8261    0.9500    0.8837        20\n",
      "           6     0.8235    0.7000    0.7568        20\n",
      "           7     0.8571    0.6000    0.7059        20\n",
      "\n",
      "    accuracy                         0.8187       160\n",
      "   macro avg     0.8256    0.8187    0.8156       160\n",
      "weighted avg     0.8256    0.8187    0.8156       160\n",
      "\n",
      "\n",
      "Batch Group 2 Results:\n",
      "Weighted Ensemble F1 Score: 0.8034503280928993\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9048    0.9500    0.9268        20\n",
      "           1     0.6522    0.7500    0.6977        20\n",
      "           2     0.9091    1.0000    0.9524        20\n",
      "           3     0.5789    0.5500    0.5641        20\n",
      "           4     1.0000    0.7000    0.8235        20\n",
      "           5     0.8182    0.9000    0.8571        20\n",
      "           6     0.8261    0.9500    0.8837        20\n",
      "           7     0.8125    0.6500    0.7222        20\n",
      "\n",
      "    accuracy                         0.8063       160\n",
      "   macro avg     0.8127    0.8063    0.8035       160\n",
      "weighted avg     0.8127    0.8063    0.8035       160\n",
      "\n",
      "\n",
      "Batch Group 3 Results:\n",
      "Weighted Ensemble F1 Score: 0.8770640235579261\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        20\n",
      "           1     0.7083    0.8500    0.7727        20\n",
      "           2     0.9412    0.8000    0.8649        20\n",
      "           3     0.7083    0.8500    0.7727        20\n",
      "           4     0.9500    0.9500    0.9500        20\n",
      "           5     0.9048    0.9500    0.9268        20\n",
      "           6     1.0000    0.8000    0.8889        20\n",
      "           7     0.9412    0.8000    0.8649        20\n",
      "\n",
      "    accuracy                         0.8750       160\n",
      "   macro avg     0.8883    0.8750    0.8771       160\n",
      "weighted avg     0.8883    0.8750    0.8771       160\n",
      "\n",
      "\n",
      "Batch Group 4 Results:\n",
      "Weighted Ensemble F1 Score: 0.8573497415581519\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8824    0.7500    0.8108        20\n",
      "           1     0.7037    0.9500    0.8085        20\n",
      "           2     0.7500    0.7500    0.7500        20\n",
      "           3     0.9412    0.8000    0.8649        20\n",
      "           4     0.9474    0.9000    0.9231        20\n",
      "           5     0.8261    0.9500    0.8837        20\n",
      "           6     0.9474    0.9000    0.9231        20\n",
      "           7     0.9444    0.8500    0.8947        20\n",
      "\n",
      "    accuracy                         0.8562       160\n",
      "   macro avg     0.8678    0.8562    0.8573       160\n",
      "weighted avg     0.8678    0.8562    0.8573       160\n",
      "\n",
      "\n",
      "Batch Group 5 Results:\n",
      "Weighted Ensemble F1 Score: 0.7871072275928144\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    0.7000    0.8000        20\n",
      "           1     0.7407    1.0000    0.8511        20\n",
      "           2     0.8636    0.9500    0.9048        20\n",
      "           3     0.7368    0.7000    0.7179        20\n",
      "           4     0.8000    0.8000    0.8000        20\n",
      "           5     0.7917    0.9500    0.8636        20\n",
      "           6     0.6818    0.7500    0.7143        20\n",
      "           7     0.9091    0.5000    0.6452        20\n",
      "\n",
      "    accuracy                         0.7937       160\n",
      "   macro avg     0.8071    0.7937    0.7871       160\n",
      "weighted avg     0.8071    0.7937    0.7871       160\n",
      "\n",
      "\n",
      "Sequential Batch F1 Scores:\n",
      "[0.8156297031855285, 0.8034503280928993, 0.8770640235579261, 0.8573497415581519, 0.7871072275928144]\n",
      "Average F1 Score: 0.828120204797464\n",
      "F1 Score Standard Deviation: 0.033753645611775525\n"
     ]
    }
   ],
   "source": [
    "test_loader = load_test_data(\"test_data\")\n",
    "\n",
    "ensembler = EnsembleTrainer(num_classes=8, device=device)\n",
    "our_results = ensembler.sequential_batch_evaluation(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
