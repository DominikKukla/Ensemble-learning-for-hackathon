{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część!\n",
    "\n",
    "## Jak poprawnie odpalić ten notebook na datasecie testowym?\n",
    "\n",
    "1. Przygotuj folder z obrazkami testowymi za pomocą schematu:\n",
    "```\n",
    "| - submission.ipynb\n",
    "|\n",
    "└───test_data\n",
    "    ├───barszcz\n",
    "    ├───bigos\n",
    "    ├───grzybowa\n",
    "    ├───Kutia\n",
    "    ├───makowiec\n",
    "    ├───piernik\n",
    "    ├───pierogi\n",
    "    └───sernik\n",
    "└───models\n",
    "    ├───resnet_18_best_f1.pth\n",
    "    ├───mobilenet_v3_large_best_f1.pth\n",
    "    ├───efficientnet_b0_best_f1.pth\n",
    "    ├───efficientnet_b1_best_f1.pth\n",
    "    ├───shufflenet_v2_x2_0_best_f1.pth\n",
    "    ├───regnet_y_800mf_best_f1.pth\n",
    "```\n",
    "\n",
    "Proszę pilnuj tego aby nazwy folderów z klasami byli takie same jak w stukturze wyżej!\n",
    "\n",
    "2. Umieść obrazki każdej klasy w odpowidającym folderze.\n",
    "\n",
    "3. Aby urochomić poniższy kod będziesz potrzebował bibliotek z requirements.txt\n",
    "\n",
    "Możesz ich zainstalować komendą: `pip install -r requirements.txt`\n",
    "\n",
    "4. Potrzebujesz też CUDA 12.1\n",
    "\n",
    "5. Puść poniższy kod!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimpi\\Desktop\\Hackathon\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import numpy as np\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root_dir = 'test_data'):\n",
    "    size_tuple = (224, 224)\n",
    "    # Define a mapping from folder names to class numbers\n",
    "    class_mapping = {\n",
    "        'barszcz': 1,\n",
    "        'bigos': 2,\n",
    "        'Kutia': 3,\n",
    "        'makowiec': 4,\n",
    "        'piernik': 5,\n",
    "        'pierogi': 6,\n",
    "        'sernik': 7,\n",
    "        'grzybowa': 8\n",
    "    }\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Load the original dataset\n",
    "    test_dataset = datasets.ImageFolder(root=root_dir, transform=transforms.Compose([\n",
    "        transforms.Resize(size_tuple),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ]))\n",
    "\n",
    "    test_dataset.class_to_idx = {k: class_mapping[k] for k in test_dataset.class_to_idx.keys()}\n",
    "\n",
    "    # Create data loaders\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import Subset\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_classes, device):\n",
    "        self.device = device\n",
    "        self.model_weights = dict()\n",
    "        \n",
    "        self.models = {\n",
    "            'efficientnet_b0': self._prepare_efficientnet_b0(num_classes, 'efficientnet_b0'),\n",
    "            'efficientnet_b1': self._prepare_efficientnet_b1(num_classes, 'efficientnet_b1'),\n",
    "            'mobilenet_v3_large': self._prepare_mobilenet_v3_large(num_classes, 'mobilenet_v3_large'),\n",
    "            'shufflenet_v2_x2_0': self._prepare_shufflenet_v2_x2_0(num_classes, 'shufflenet_v2_x2_0'),\n",
    "        }\n",
    "\n",
    "\n",
    "    def _prepare_efficientnet_b0(self, num_classes, model_name):\n",
    "        model = models.efficientnet_b0(weights='DEFAULT')\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint['best_val_f1']\n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def _prepare_efficientnet_b1(self, num_classes, model_name):\n",
    "        model = models.efficientnet_b1(weights=\"IMAGENET1K_V2\")\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint['best_val_f1']\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def _prepare_mobilenet_v3_large(self, num_classes, model_name):\n",
    "        model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "        \n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint['best_val_f1']\n",
    "        \n",
    "        return model.to(self.device)\n",
    "\n",
    "\n",
    "    def _prepare_shufflenet_v2_x2_0(self, num_classes, model_name):\n",
    "        model = models.shufflenet_v2_x2_0(weights='DEFAULT')\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "        # Load the saved checkpoint\n",
    "        checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
    "\n",
    "        # Load the model weights\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Optional: Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        self.model_weights[model_name] = checkpoint['best_val_f1']\n",
    "        \n",
    "        return model.to(self.device)\n",
    "\n",
    "\n",
    "\n",
    "    def sequential_batch_evaluation(self, dataloader, batch_size=20):\n",
    "        # Total number of classes\n",
    "        num_classes = len(dataloader.dataset.classes)\n",
    "        \n",
    "        # Create a list to track F1 scores for each sequential batch\n",
    "        sequential_f1_scores = []\n",
    "        \n",
    "        # Get the total number of images\n",
    "        total_images = len(dataloader.dataset)\n",
    "        \n",
    "        # Calculate how many full batches of 10 images per class we can process\n",
    "        images_per_class = total_images // num_classes\n",
    "        batches_per_class = images_per_class // batch_size\n",
    "        \n",
    "        # Iterate through sequential batches\n",
    "        for batch_group in range(batches_per_class):\n",
    "            # Reset ensemble probabilities and labels for this batch group\n",
    "            all_ensemble_probs = defaultdict(list)\n",
    "            all_labels = []\n",
    "            \n",
    "            # Process 10 images from each class\n",
    "            for class_idx in range(num_classes):\n",
    "                start_idx = (batch_group * batch_size) + (class_idx * images_per_class)\n",
    "                end_idx = start_idx + batch_size\n",
    "                \n",
    "                # Create a subset for this specific slice of images\n",
    "                subset_indices = list(range(start_idx, end_idx))\n",
    "                subset = Subset(dataloader.dataset, subset_indices)\n",
    "                \n",
    "                # Create a new dataloader for this subset\n",
    "                subset_loader = torch.utils.data.DataLoader(\n",
    "                    subset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=False\n",
    "                )\n",
    "                \n",
    "                # Process this subset\n",
    "                for images, labels in subset_loader:\n",
    "                    images = images.to(self.device)\n",
    "                    \n",
    "                    # Collect probabilities from each model\n",
    "                    for model_name, model in self.models.items():\n",
    "                        probs = torch.softmax(model(images), dim=1)\n",
    "                        all_ensemble_probs[model_name].append(probs.detach().cpu())\n",
    "                    \n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Normalize model weights\n",
    "            n = 5\n",
    "            self.model_weights_now = {k: v ** n for k, v in self.model_weights.items()}\n",
    "            total_weight = sum(self.model_weights_now.values())\n",
    "            model_weights_normalized = {model: weight / total_weight for model, weight in self.model_weights_now.items()}\n",
    "            \n",
    "            # Calculate ensemble predictions\n",
    "            all_ensemble_preds = []\n",
    "            for i in range(len(list(all_ensemble_probs.values())[0])):\n",
    "                weighted_preds = []\n",
    "                for model_name in list(self.models.keys()):\n",
    "                    weight = model_weights_normalized.get(model_name, 0.0)\n",
    "                    if weight == 0.0:\n",
    "                        print(f\"Warning: No weight for model {model_name}\")\n",
    "                        break\n",
    "                    weighted_preds.append(all_ensemble_probs[model_name][i] * weight)\n",
    "                \n",
    "                ensemble_probs = torch.sum(torch.stack(weighted_preds), dim=0)\n",
    "                _, ensemble_pred = torch.max(ensemble_probs, 1)\n",
    "                all_ensemble_preds.extend(ensemble_pred.cpu().numpy())\n",
    "            \n",
    "            # Calculate F1 score for this batch group\n",
    "            batch_f1 = f1_score(all_labels, all_ensemble_preds, average='weighted')\n",
    "            sequential_f1_scores.append(batch_f1)\n",
    "            \n",
    "            # Print detailed report for this batch group\n",
    "            print(f\"\\nBatch Group {batch_group + 1} Results:\")\n",
    "            print(f\"Weighted Ensemble F1 Score: {batch_f1}\")\n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(classification_report(all_labels, all_ensemble_preds, \n",
    "                                        digits=4,  \n",
    "                                        zero_division=0))\n",
    "        \n",
    "        # Print overall summary of F1 scores\n",
    "        print(\"\\nSequential Batch F1 Scores:\")\n",
    "        print(sequential_f1_scores)\n",
    "        print(f\"Average F1 Score: {np.mean(sequential_f1_scores)}\")\n",
    "        print(f\"F1 Score Standard Deviation: {np.std(sequential_f1_scores)}\")\n",
    "        \n",
    "        return sequential_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_22944\\776839665.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_22944\\776839665.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_22944\\776839665.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n",
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_22944\\776839665.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'models/{model_name}_best_f1.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Group 1 Results:\n",
      "Weighted Ensemble F1 Score: 1.0\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    1.0000    1.0000        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     1.0000    1.0000    1.0000        20\n",
      "           5     1.0000    1.0000    1.0000        20\n",
      "           6     1.0000    1.0000    1.0000        20\n",
      "           7     1.0000    1.0000    1.0000        20\n",
      "\n",
      "    accuracy                         1.0000       160\n",
      "   macro avg     1.0000    1.0000    1.0000       160\n",
      "weighted avg     1.0000    1.0000    1.0000       160\n",
      "\n",
      "\n",
      "Batch Group 2 Results:\n",
      "Weighted Ensemble F1 Score: 1.0\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    1.0000    1.0000        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     1.0000    1.0000    1.0000        20\n",
      "           5     1.0000    1.0000    1.0000        20\n",
      "           6     1.0000    1.0000    1.0000        20\n",
      "           7     1.0000    1.0000    1.0000        20\n",
      "\n",
      "    accuracy                         1.0000       160\n",
      "   macro avg     1.0000    1.0000    1.0000       160\n",
      "weighted avg     1.0000    1.0000    1.0000       160\n",
      "\n",
      "\n",
      "Batch Group 3 Results:\n",
      "Weighted Ensemble F1 Score: 0.9873234916559692\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    1.0000    1.0000        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     1.0000    1.0000    1.0000        20\n",
      "           5     1.0000    0.9000    0.9474        20\n",
      "           6     1.0000    1.0000    1.0000        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9875       160\n",
      "   macro avg     0.9881    0.9875    0.9873       160\n",
      "weighted avg     0.9881    0.9875    0.9873       160\n",
      "\n",
      "\n",
      "Batch Group 4 Results:\n",
      "Weighted Ensemble F1 Score: 0.9812382739212009\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     1.0000    0.9500    0.9744        20\n",
      "           5     0.9524    1.0000    0.9756        20\n",
      "           6     1.0000    0.9500    0.9744        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9812       160\n",
      "   macro avg     0.9821    0.9812    0.9812       160\n",
      "weighted avg     0.9821    0.9812    0.9812       160\n",
      "\n",
      "\n",
      "Batch Group 5 Results:\n",
      "Weighted Ensemble F1 Score: 0.9364373858918148\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9048    0.9500    0.9268        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     0.9091    1.0000    0.9524        20\n",
      "           3     1.0000    0.9000    0.9474        20\n",
      "           4     0.8333    1.0000    0.9091        20\n",
      "           5     1.0000    0.7500    0.8571        20\n",
      "           6     0.9474    0.9000    0.9231        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9375       160\n",
      "   macro avg     0.9434    0.9375    0.9364       160\n",
      "weighted avg     0.9434    0.9375    0.9364       160\n",
      "\n",
      "\n",
      "Batch Group 6 Results:\n",
      "Weighted Ensemble F1 Score: 0.9377830180514003\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8500    0.9189        20\n",
      "           1     0.9474    0.9000    0.9231        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     0.9091    1.0000    0.9524        20\n",
      "           4     0.8261    0.9500    0.8837        20\n",
      "           5     1.0000    0.9000    0.9474        20\n",
      "           6     0.9048    0.9500    0.9268        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9375       160\n",
      "   macro avg     0.9425    0.9375    0.9378       160\n",
      "weighted avg     0.9425    0.9375    0.9378       160\n",
      "\n",
      "\n",
      "Batch Group 7 Results:\n",
      "Weighted Ensemble F1 Score: 0.8936610559239078\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.9000    0.8571        20\n",
      "           1     0.8696    1.0000    0.9302        20\n",
      "           2     1.0000    0.7500    0.8571        20\n",
      "           3     1.0000    0.9000    0.9474        20\n",
      "           4     0.8261    0.9500    0.8837        20\n",
      "           5     1.0000    0.8500    0.9189        20\n",
      "           6     0.8636    0.9500    0.9048        20\n",
      "           7     0.8500    0.8500    0.8500        20\n",
      "\n",
      "    accuracy                         0.8938       160\n",
      "   macro avg     0.9034    0.8937    0.8937       160\n",
      "weighted avg     0.9034    0.8938    0.8937       160\n",
      "\n",
      "\n",
      "Batch Group 8 Results:\n",
      "Weighted Ensemble F1 Score: 0.9496044872970419\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.9000    0.9000        20\n",
      "           1     0.9091    1.0000    0.9524        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     0.9444    0.8500    0.8947        20\n",
      "           4     0.9091    1.0000    0.9524        20\n",
      "           5     1.0000    0.9000    0.9474        20\n",
      "           6     0.9524    1.0000    0.9756        20\n",
      "           7     1.0000    1.0000    1.0000        20\n",
      "\n",
      "    accuracy                         0.9500       160\n",
      "   macro avg     0.9519    0.9500    0.9496       160\n",
      "weighted avg     0.9519    0.9500    0.9496       160\n",
      "\n",
      "\n",
      "Batch Group 9 Results:\n",
      "Weighted Ensemble F1 Score: 0.9553145194913487\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        20\n",
      "           1     0.9524    1.0000    0.9756        20\n",
      "           2     0.9500    0.9500    0.9500        20\n",
      "           3     1.0000    0.8000    0.8889        20\n",
      "           4     0.9524    1.0000    0.9756        20\n",
      "           5     1.0000    0.9500    0.9744        20\n",
      "           6     0.9524    1.0000    0.9756        20\n",
      "           7     0.9048    0.9500    0.9268        20\n",
      "\n",
      "    accuracy                         0.9563       160\n",
      "   macro avg     0.9580    0.9563    0.9553       160\n",
      "weighted avg     0.9580    0.9563    0.9553       160\n",
      "\n",
      "\n",
      "Batch Group 10 Results:\n",
      "Weighted Ensemble F1 Score: 0.9683858156178438\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9500    0.9744        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    1.0000    1.0000        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     0.9444    0.8500    0.8947        20\n",
      "           5     0.9500    0.9500    0.9500        20\n",
      "           6     0.9091    1.0000    0.9524        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9688       160\n",
      "   macro avg     0.9695    0.9688    0.9684       160\n",
      "weighted avg     0.9695    0.9688    0.9684       160\n",
      "\n",
      "\n",
      "Sequential Batch F1 Scores:\n",
      "[1.0, 1.0, 0.9873234916559692, 0.9812382739212009, 0.9364373858918148, 0.9377830180514003, 0.8936610559239078, 0.9496044872970419, 0.9553145194913487, 0.9683858156178438]\n",
      "Average F1 Score: 0.9609748047850527\n",
      "F1 Score Standard Deviation: 0.031682998467495935\n"
     ]
    }
   ],
   "source": [
    "test_loader = load_test_data(\"test_data2secuantional_our\")\n",
    "\n",
    "ensembler = EnsembleTrainer(num_classes=8, device=device)\n",
    "our_results = ensembler.sequential_batch_evaluation(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(root_dir = 'test_data'):\n",
    "    size_tuple = (224, 224)\n",
    "    # Define a mapping from folder names to class numbers\n",
    "    # class_mapping = {\n",
    "    #     'barszcz': 1,\n",
    "    #     'bigos': 2,\n",
    "    #     'Kutia': 3,\n",
    "    #     'makowiec': 4,\n",
    "    #     'piernik': 5,\n",
    "    #     'pierogi': 6,\n",
    "    #     'sernik': 7,\n",
    "    #     'grzybowa': 8\n",
    "    # }\n",
    "    \n",
    "    class_mapping = {\n",
    "        'barszcz czerwony': 1,\n",
    "        'bigos': 2,\n",
    "        'kutia': 3,\n",
    "        'makowiec': 4,\n",
    "        'pierniki': 5,\n",
    "        'pierogi': 6,\n",
    "        'sernik': 7,\n",
    "        'zupa grzybowa': 8\n",
    "    }\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Load the original dataset\n",
    "    test_dataset = datasets.ImageFolder(root=root_dir, transform=transforms.Compose([\n",
    "        transforms.Resize(size_tuple),\n",
    "        transforms.ToTensor(),\n",
    "#        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ]))\n",
    "\n",
    "    test_dataset.class_to_idx = {k: class_mapping[k] for k in test_dataset.class_to_idx.keys()}\n",
    "\n",
    "    # Create data loaders\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_classes, device):\n",
    "        self.device = device\n",
    "        self.model_weights = {'resnet50': 1}\n",
    "        \n",
    "        self.models = {\n",
    "            'resnet50': self._prepare_resnet50(num_classes, 'resnet50'),\n",
    "        }\n",
    "\n",
    "\n",
    "    def _prepare_resnet50(self, num_classes, model_name):\n",
    "        # Wczytanie modelu\n",
    "        model_ft = models.resnet50(weights=None)\n",
    "\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model_ft.load_state_dict(torch.load(\"model_weights.pth\", map_location=torch.device(device)))\n",
    "\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "        return model_ft.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    def sequential_batch_f1_score(self, dataloader, batch_size=20, average='weighted'):\n",
    "        # Total number of classes\n",
    "        num_classes = len(dataloader.dataset.classes)\n",
    "        \n",
    "        # Create a list to track F1 scores for each sequential batch\n",
    "        sequential_f1_scores = []\n",
    "        \n",
    "        # Get the total number of images\n",
    "        total_images = len(dataloader.dataset)\n",
    "        \n",
    "        # Calculate how many full batches of 10 images per class we can process\n",
    "        images_per_class = total_images // num_classes\n",
    "        batches_per_class = images_per_class // batch_size\n",
    "        \n",
    "        # Assuming only one model in self.models\n",
    "        model = list(self.models.values())[0]\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        \n",
    "        # Iterate through sequential batches\n",
    "        for batch_group in range(batches_per_class):\n",
    "            # Reset labels and predictions for this batch group\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "            \n",
    "            # Process 10 images from each class\n",
    "            for class_idx in range(num_classes):\n",
    "                start_idx = (batch_group * batch_size) + (class_idx * images_per_class)\n",
    "                end_idx = start_idx + batch_size\n",
    "                \n",
    "                # Create a subset for this specific slice of images\n",
    "                subset_indices = list(range(start_idx, end_idx))\n",
    "                subset = Subset(dataloader.dataset, subset_indices)\n",
    "                \n",
    "                # Create a new dataloader for this subset\n",
    "                subset_loader = torch.utils.data.DataLoader(\n",
    "                    subset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=False\n",
    "                )\n",
    "                \n",
    "                # Process this subset\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in subset_loader:\n",
    "                        images = images.to(self.device)\n",
    "                        \n",
    "                        # Get model predictions\n",
    "                        outputs = model(images)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        \n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Calculate F1 score for this batch group\n",
    "            batch_f1 = f1_score(all_labels, all_preds, average=average)\n",
    "            sequential_f1_scores.append(batch_f1)\n",
    "            \n",
    "            # Print detailed report for this batch group\n",
    "            print(f\"\\nBatch Group {batch_group + 1} Results:\")\n",
    "            print(f\"Model F1 Score ({average}): {batch_f1}\")\n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(classification_report(all_labels, all_preds, \n",
    "                                        digits=4,  \n",
    "                                        zero_division=0))\n",
    "        \n",
    "        # Print overall summary of F1 scores\n",
    "        print(\"\\nSequential Batch F1 Scores:\")\n",
    "        print(sequential_f1_scores)\n",
    "        print(f\"Average F1 Score: {np.mean(sequential_f1_scores)}\")\n",
    "        print(f\"F1 Score Standard Deviation: {np.std(sequential_f1_scores)}\")\n",
    "        \n",
    "        return sequential_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_22944\\4245590292.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_ft.load_state_dict(torch.load(\"model_weights.pth\", map_location=torch.device(device)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Batch Group 1 Results:\n",
      "Model F1 Score (weighted): 0.917666102455339\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7692    1.0000    0.8696        20\n",
      "           1     0.9524    1.0000    0.9756        20\n",
      "           2     1.0000    1.0000    1.0000        20\n",
      "           3     1.0000    0.9500    0.9744        20\n",
      "           4     0.9000    0.9000    0.9000        20\n",
      "           5     0.9333    0.7000    0.8000        20\n",
      "           6     0.8947    0.8500    0.8718        20\n",
      "           7     0.9500    0.9500    0.9500        20\n",
      "\n",
      "    accuracy                         0.9187       160\n",
      "   macro avg     0.9250    0.9187    0.9177       160\n",
      "weighted avg     0.9250    0.9187    0.9177       160\n",
      "\n",
      "\n",
      "Batch Group 2 Results:\n",
      "Model F1 Score (weighted): 0.943201343400242\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    1.0000    0.9302        20\n",
      "           1     1.0000    0.9000    0.9474        20\n",
      "           2     0.9091    1.0000    0.9524        20\n",
      "           3     1.0000    0.9500    0.9744        20\n",
      "           4     0.9500    0.9500    0.9500        20\n",
      "           5     1.0000    0.8000    0.8889        20\n",
      "           6     0.9500    0.9500    0.9500        20\n",
      "           7     0.9091    1.0000    0.9524        20\n",
      "\n",
      "    accuracy                         0.9437       160\n",
      "   macro avg     0.9485    0.9437    0.9432       160\n",
      "weighted avg     0.9485    0.9437    0.9432       160\n",
      "\n",
      "\n",
      "Batch Group 3 Results:\n",
      "Model F1 Score (weighted): 0.9297848043635639\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756        20\n",
      "           1     1.0000    0.9500    0.9744        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     1.0000    0.8500    0.9189        20\n",
      "           4     0.9091    1.0000    0.9524        20\n",
      "           5     1.0000    0.7000    0.8235        20\n",
      "           6     0.8696    1.0000    0.9302        20\n",
      "           7     0.8000    1.0000    0.8889        20\n",
      "\n",
      "    accuracy                         0.9313       160\n",
      "   macro avg     0.9414    0.9313    0.9298       160\n",
      "weighted avg     0.9414    0.9313    0.9298       160\n",
      "\n",
      "\n",
      "Batch Group 4 Results:\n",
      "Model F1 Score (weighted): 0.9377441474825197\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    1.0000    0.9302        20\n",
      "           1     1.0000    1.0000    1.0000        20\n",
      "           2     1.0000    0.8500    0.9189        20\n",
      "           3     1.0000    0.8500    0.9189        20\n",
      "           4     0.9500    0.9500    0.9500        20\n",
      "           5     1.0000    0.9500    0.9744        20\n",
      "           6     0.8182    0.9000    0.8571        20\n",
      "           7     0.9091    1.0000    0.9524        20\n",
      "\n",
      "    accuracy                         0.9375       160\n",
      "   macro avg     0.9434    0.9375    0.9377       160\n",
      "weighted avg     0.9434    0.9375    0.9377       160\n",
      "\n",
      "\n",
      "Batch Group 5 Results:\n",
      "Model F1 Score (weighted): 0.9366172445440739\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    1.0000    0.9091        20\n",
      "           1     0.9524    1.0000    0.9756        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "           4     1.0000    0.7500    0.8571        20\n",
      "           5     0.9048    0.9500    0.9268        20\n",
      "           6     0.9474    0.9000    0.9231        20\n",
      "           7     0.9048    0.9500    0.9268        20\n",
      "\n",
      "    accuracy                         0.9375       160\n",
      "   macro avg     0.9428    0.9375    0.9366       160\n",
      "weighted avg     0.9428    0.9375    0.9366       160\n",
      "\n",
      "\n",
      "Batch Group 6 Results:\n",
      "Model F1 Score (weighted): 0.9239330244545265\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    1.0000    0.9091        20\n",
      "           1     1.0000    0.9000    0.9474        20\n",
      "           2     0.9375    0.7500    0.8333        20\n",
      "           3     0.9091    1.0000    0.9524        20\n",
      "           4     1.0000    0.8500    0.9189        20\n",
      "           5     0.8636    0.9500    0.9048        20\n",
      "           6     0.9524    1.0000    0.9756        20\n",
      "           7     0.9500    0.9500    0.9500        20\n",
      "\n",
      "    accuracy                         0.9250       160\n",
      "   macro avg     0.9307    0.9250    0.9239       160\n",
      "weighted avg     0.9307    0.9250    0.9239       160\n",
      "\n",
      "\n",
      "Batch Group 7 Results:\n",
      "Model F1 Score (weighted): 0.9108549787304602\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    1.0000    0.9091        20\n",
      "           1     1.0000    0.8500    0.9189        20\n",
      "           2     0.8889    0.8000    0.8421        20\n",
      "           3     0.9048    0.9500    0.9268        20\n",
      "           4     1.0000    0.7500    0.8571        20\n",
      "           5     0.8636    0.9500    0.9048        20\n",
      "           6     0.9091    1.0000    0.9524        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "\n",
      "    accuracy                         0.9125       160\n",
      "   macro avg     0.9190    0.9125    0.9109       160\n",
      "weighted avg     0.9190    0.9125    0.9109       160\n",
      "\n",
      "\n",
      "Batch Group 8 Results:\n",
      "Model F1 Score (weighted): 0.912289312488211\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    1.0000    0.9302        20\n",
      "           1     1.0000    0.9000    0.9474        20\n",
      "           2     0.9412    0.8000    0.8649        20\n",
      "           3     0.8636    0.9500    0.9048        20\n",
      "           4     1.0000    0.8500    0.9189        20\n",
      "           5     0.9000    0.9000    0.9000        20\n",
      "           6     0.9474    0.9000    0.9231        20\n",
      "           7     0.8333    1.0000    0.9091        20\n",
      "\n",
      "    accuracy                         0.9125       160\n",
      "   macro avg     0.9194    0.9125    0.9123       160\n",
      "weighted avg     0.9194    0.9125    0.9123       160\n",
      "\n",
      "\n",
      "Batch Group 9 Results:\n",
      "Model F1 Score (weighted): 0.9437298083221599\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    1.0000    0.9302        20\n",
      "           1     1.0000    0.9000    0.9474        20\n",
      "           2     1.0000    0.9500    0.9744        20\n",
      "           3     1.0000    0.9000    0.9474        20\n",
      "           4     0.9091    1.0000    0.9524        20\n",
      "           5     1.0000    0.8500    0.9189        20\n",
      "           6     0.9091    1.0000    0.9524        20\n",
      "           7     0.9048    0.9500    0.9268        20\n",
      "\n",
      "    accuracy                         0.9437       160\n",
      "   macro avg     0.9491    0.9437    0.9437       160\n",
      "weighted avg     0.9491    0.9437    0.9437       160\n",
      "\n",
      "\n",
      "Batch Group 10 Results:\n",
      "Model F1 Score (weighted): 0.9361408697312571\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    1.0000    0.8889        20\n",
      "           1     0.9500    0.9500    0.9500        20\n",
      "           2     0.9500    0.9500    0.9500        20\n",
      "           3     1.0000    0.9500    0.9744        20\n",
      "           4     0.9091    1.0000    0.9524        20\n",
      "           5     1.0000    0.7000    0.8235        20\n",
      "           6     0.9524    1.0000    0.9756        20\n",
      "           7     1.0000    0.9500    0.9744        20\n",
      "\n",
      "    accuracy                         0.9375       160\n",
      "   macro avg     0.9452    0.9375    0.9361       160\n",
      "weighted avg     0.9452    0.9375    0.9361       160\n",
      "\n",
      "\n",
      "Sequential Batch F1 Scores:\n",
      "[0.917666102455339, 0.943201343400242, 0.9297848043635639, 0.9377441474825197, 0.9366172445440739, 0.9239330244545265, 0.9108549787304602, 0.912289312488211, 0.9437298083221599, 0.9361408697312571]\n",
      "Average F1 Score: 0.9291961635972354\n",
      "F1 Score Standard Deviation: 0.011691755312092832\n"
     ]
    }
   ],
   "source": [
    "test_loader = load_test_data(\"test_data2secuantional\")\n",
    "\n",
    "ensembler = EnsembleTrainer(num_classes=8, device=device)\n",
    "their_results = ensembler.sequential_batch_f1_score(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(their_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for i in range(len(their_results)) if our_results[i] > their_results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_classes, device):\n",
    "        self.device = device\n",
    "        self.model_weights = {'resnet18': 1}\n",
    "        \n",
    "        self.models = {\n",
    "            'resnet18': self._prepare_resnet18(num_classes, 'resnet18'),\n",
    "        }\n",
    "\n",
    "\n",
    "    def _prepare_resnet18(self, num_classes, model_name):\n",
    "        model_ft = CustomResNet18(8)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        model_ft.load_state_dict(torch.load(\"CustomResNet18_epoch_20.pth\", map_location=torch.device(device)))\n",
    "\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "        return model_ft.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_f1_score(self, dataloader, average='weighted'):\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                \n",
    "                # Assuming only one model in self.models\n",
    "                model = list(self.models.values())[0]\n",
    "                model.eval()  # Set the model to evaluation mode\n",
    "                \n",
    "                # Get model predictions\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate F1 score and print classification report\n",
    "        f1 = f1_score(all_labels, all_preds, average=average)\n",
    "        print(f\"Model F1 Score ({average}): {f1}\")\n",
    "        \n",
    "        # Print detailed classification report\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(all_labels, all_preds, \n",
    "                                    digits=4,  # 4 decimal places for precision/recall/f1\n",
    "                                    zero_division=0))  # handles classes with zero samples\n",
    "        \n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimpi\\Desktop\\Hackathon\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dimpi\\Desktop\\Hackathon\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\dimpi\\AppData\\Local\\Temp\\ipykernel_23976\\437200705.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_ft.load_state_dict(torch.load(\"CustomResNet18_epoch_20.pth\", map_location=torch.device(device)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Model F1 Score (weighted): 0.9292446719595162\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9370    0.9754    0.9558       122\n",
      "           1     0.9718    0.9247    0.9477       186\n",
      "           2     0.9091    0.9353    0.9220       139\n",
      "           3     0.9409    0.9215    0.9311       242\n",
      "           4     0.8832    0.9098    0.8963       133\n",
      "           5     0.8656    0.9877    0.9226       163\n",
      "           6     0.9517    0.8914    0.9206       221\n",
      "           7     0.9586    0.9153    0.9364       177\n",
      "\n",
      "    accuracy                         0.9291      1383\n",
      "   macro avg     0.9272    0.9326    0.9291      1383\n",
      "weighted avg     0.9311    0.9291    0.9292      1383\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9292446719595162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = load_test_data(\"test_data_dominik\")\n",
    "\n",
    "ensembler = EnsembleTrainer(num_classes=8, device=device)\n",
    "ensembler.calculate_f1_score(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
